# INTERNSHIP DETAILS
    Organization: Essence
    Intern Name: Renu Bojja
    Student ID: 1RVU22CSE129
    Duration: January 10, 2025 – April 3, 2025

# OVERVIEW
This internship was all about diving into language models (LMs) and large language models (LLMs), exploring how they work, and figuring out how to fine-tune them for specific tasks. 

# WHAT I DID
    1. Exploring Popular Language Models
        Experimented with GPT-2, BERT, T5, XLNet, and TinyBERT.
        Compared:
        Speed: How fast they tokenize and generate outputs.
        Creativity: How good they are at generating meaningful text.
        Computation: How resource-heavy each model is.
    2. Fine-Tuning Models
        Fine-tuned BERT for specific tasks.
        Started working on TinyBERT to see if a smaller model could still perform well.
        Learned how TinyBERT and BERT differ, especially in terms of accuracy and computation time.
        Faced issues with TinyBERT being slower than expected, which I’m working on fixing.
    3. Comparing Models
        Measured tokenization time on real data (task titles from a dataset).
        Observations:
        Fastest Tokenization: T5 was the quickest, followed by GPT, XLNet, TinyBERT, and then BERT.
        Even smaller models like TinyBERT don’t always save as much time as expected.
    4. Challenges
        API issues: Couldn’t fully explore GPT-3/4 due to lack of access to their API keys.
        Hugging Face token problems: Logged in and got a token, but it wasn’t working, so I had to troubleshoot.

# WHAT I LEARNED
    1. How Language Models Work:    
        Each model has its strengths, like speed, creativity, or accuracy.
        Smaller models (e.g., TinyBERT) can be good alternatives but come with trade-offs.
    2. Practical ML Skills:    
        Fine-tuning pre-trained models for specific use cases.
        Measuring and comparing performance metrics like tokenization time.
    3. Dealing with Real-World Problems:    
        Managing limited computing resources.
        Handling authentication and access issues with APIs and tools.
    4. Efficiency Matters:    
        Bigger isn’t always better, but smaller models aren’t perfect either.
        Balancing speed and accuracy is key.
